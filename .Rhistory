#set the path
path <- paste(base,directory,sep="",collapse=NULL)
#get the file List in that directory
fileList <- list.files(path)
#extract the file names and store as numeric for comparison
file.names <- as.numeric(sub("\\.csv$","",fileList))
#select files to be imported based on the user input or default
selected.files <- fileList[match(id,file.names)]
#import data
Data <- lapply(file.path(path,selected.files),read.csv)
nobs <- vector(mode="integer", length = length(Data))
for (i in 1:length(Data)) {
nobs[i] <- sum(complete.cases(Data[[i]]))
}
return(data.frame(id, nobs))
}
complete("specdata", 1)
complete("specdata", c(2, 4, 8, 10, 12))
complete("specdata", 30:25)
complete("specdata", 3)
?cor
directory <- "C:/Coursera/R Programming/Programming Assignments/Assignment 1/specdata/"
id = 1:332
x <- complete(directory,id)
directory <- "specdata"
x <- complete(directory,id)
x
threshold <- 150
y <- subset(x, nobs > threshold)
cor_result <- vector(mode="numeric", length = nrow(y))
for (i in 1:nrow(y)) {
sulfate <- df_list[[y$id[i]]][complete.cases(df_list[[y$id[i]]]), ]$sulfate
nitrate <- df_list[[y$id[i]]][complete.cases(df_list[[y$id[i]]]), ]$nitrate
cor_result[i] <- cor(sulfate, nitrate)
}
base <- "C:/Coursera/R Programming/Programming Assignments/Assignment 1/"
#set the path
path <- paste(base,directory,sep="",collapse=NULL)
#get the file List in that directory
fileList <- list.files(path)
#extract the file names and store as numeric for comparison
file.names <- as.numeric(sub("\\.csv$","",fileList))
#select files to be imported based on the user input or default
selected.files <- fileList[match(id,file.names)]
#import data
Data <- lapply(file.path(path,selected.files),read.csv)
cor_result <- vector(mode="numeric", length = nrow(y))
for (i in 1:nrow(y)) {
sulfate <- Data[[y$id[i]]][complete.cases(Data[[y$id[i]]]), ]$sulfate
nitrate <- Data[[y$id[i]]][complete.cases(Data[[y$id[i]]]), ]$nitrate
cor_result[i] <- cor(sulfate, nitrate)
}
head(cor_result)
summary(cor_result)
## creates a special "matrix" object that can cache its inverse.
makeCacheMatrix <- function(x = matrix()) {
i <- NULL
set <- function(y) {
x <<- y
i <<- NULL
}
get <- function() x
setinverse <- function(inverse) i <<- inverse
getinverse <- function() i
list(set = set, get = get, setinverse = setinverse, getinverse = getinverse)
}
##  computes the inverse of the special "matrix" returned by
## makeCacheMatrix above. If the inverse has already been calculated
## (and the matrix has not changed), then the cachesolve should retrieve
## the inverse from the cache.
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
i <- x$getinverse()
if (!is.null(i)) {
message("getting cached data")
return(i)
}
data <- x$get()
i <- solve(data)
x$setinverse(i)
return(i)
}
x <- matrix(c(1, 2, 3, 4), nrow = 2, ncol = 2, byrow = TRUE)
m <- makeCacheMatrix(x)
# original matrix
m$get()
# first call is uncached
cacheSolve(m)
# second call is cached
cacheSolve(m)
x
m
?inverse
?solve
x
colve(x)
solve(x)
makeCacheMatrix <- function(x = matrix()) {
+     i <- NULL
+     set <- function(y) {
+         x <<- y
+         i <<- NULL
+     }
+
+     get <- function() x
+     setinverse <- function(inverse) i <<- inverse
+     getinverse <- function() i
+     list(set = set, get = get, setinverse = setinverse, getinverse = getinverse)
+ }
makeCacheMatrix <- function(x = matrix()) {
i <- NULL
set <- function(y) {
x <<- y
i <<- NULL
}
get <- function() x
setinverse <- function(inverse) i <<- inverse
getinverse <- function() i
list(set = set, get = get, setinverse = setinverse, getinverse = getinverse)
}
get
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
i <- x$getinverse()
if (!is.null(i)) {
message("getting cached data")
return(i)
}
data <- x$get()
i <- solve(data)
x$setinverse(i)
return(i)
}
x <- matrix(c(1, 2, 3, 4), nrow = 2, ncol = 2, byrow = TRUE)
m <- makeCacheMatrix(x)
?m
args(m)
m
m$get()
i <- x$getinverse()
i <- m$getinverse()
data <- m$get()
i <- solve(data)
m$setinverse(i)
m
i <- m$getinverse()
View(i)
View(i)
i <-m
i<-x
i <- m$getinverse()
m(1)
m
get
get(x)
m$get()
x$get()
m$get()
clear
clr
## creates a special "matrix" object that can cache its inverse.
makeCacheMatrix <- function(x = matrix()) {
i <- NULL
set <- function(y) {
x <<- y
i <<- NULL
}
get <- function() x
setinverse <- function(inverse) i <<- inverse
getinverse <- function() i
list(set = set, get = get, setinverse = setinverse, getinverse = getinverse)
}
##  computes the inverse of the special "matrix" returned by
## makeCacheMatrix above. If the inverse has already been calculated
## (and the matrix has not changed), then the cachesolve should retrieve
## the inverse from the cache.
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
i <- x$getinverse()
if (!is.null(i)) {
message("getting cached data")
return(i)
}
data <- x$get()
i <- solve(data)
x$setinverse(i)
return(i)
}
x <- matrix(c(1, 2, 3, 4), nrow = 2, ncol = 2, byrow = TRUE)
m <- makeCacheMatrix(x)
# original matrix
m$get()
cacheSolve(m)
i
cacheSolve(m)
m$getinverse()
ls(environment(m))
ls(environment(x))
ls(environment(m))
ls(environment(makecachematrix))
get("i",environment(m))
## creates a special "matrix" object that can cache its inverse.
makeCacheMatrix <- function(x = matrix()) {
i <- NULL
set <- function(y) {
x <<- y
i <<- NULL
}
get <- function() x
setinverse <- function(inverse) i <<- inverse
getinverse <- function() i
list(set = set, get = get, setinverse = setinverse, getinverse = getinverse)
}
##  computes the inverse of the special "matrix" returned by
## makeCacheMatrix above. If the inverse has already been calculated
## (and the matrix has not changed), then the cachesolve should retrieve
## the inverse from the cache.
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
i <- x$getinverse()
if (!is.null(i)) {
message("getting cached data")
return(i)
}
data <- x$get()
i <- solve(data)
x$setinverse(i)
return(i)
}
x <- matrix(c(1, 2, 3, 4), nrow = 2, ncol = 2, byrow = TRUE)
debug("makeCacheMatrix")
debug("cachesolve")
debug("cacheSolve")
m <- makeCacheMatrix(x)
i
m$get()
debug("makeCacheMatrix")
m$get()
debug("m")
m
cacheSolve(m)
browser
browser()
## creates a special "matrix" object that can cache its inverse.
makeCacheMatrix <- function(x = matrix()) {
i <- NULL
set <- function(y) {
x <<- y
i <<- NULL
}
get <- function() x
setinverse <- function(inverse) i <<- inverse
getinverse <- function() i
list(set = set, get = get, setinverse = setinverse, getinverse = getinverse)
}
##  computes the inverse of the special "matrix" returned by
## makeCacheMatrix above. If the inverse has already been calculated
## (and the matrix has not changed), then the cachesolve should retrieve
## the inverse from the cache.
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
i <- x$getinverse()
if (!is.null(i)) {
message("getting cached data")
return(i)
}
data <- x$get()
i <- solve(data)
x$setinverse(i)
return(i)
}
x <- matrix(c(1, 2, 3, 4), nrow = 2, ncol = 2, byrow = TRUE)
browser()
m <- makeCacheMatrix(x)
cacheSolve(m)
cacheSolve(m)
debug("set")
debug("makeCacheMatrix")
rm x
rm "x"
rm
?rm
rm(x)
rm(m)
x <- matrix(c(1, 2, 3, 4), nrow = 2, ncol = 2, byrow = TRUE)
m <- makeCacheMatrix(x)
debug("set")
?debug
debug("set")
debug("makeCacheMatrix")
m$get()
cacheSolve(m)
cacheSolve(m)
## creates a special "matrix" object that can cache its inverse.
makeCacheMatrix <- function(base_matrix = matrix()) {
inv_matrix <- NULL
set <- function(passed_matrix) {
base_matrix <<- passed_matrix
inv_matrix <<- NULL
}
get <- function() base_matrix
setinverse <- function(inverse) inv_matrix <<- inverse
getinverse <- function() inv_matrix
list(set = set, get = get, setinverse = setinverse, getinverse = getinverse)
}
##  computes the inverse of the special "matrix" returned by
## makeCacheMatrix above. If the inverse has already been calculated
## (and the matrix has not changed), then the cachesolve should retrieve
## the inverse from the cache.
cacheSolve <- function(cache_matrix, ...) {
## Return a matrix that is the inverse of 'x'
inv_matrix <- cache_matrix$getinverse()
if (!is.null(inv_matrix)) {
message("getting cached data")
return(inv_matrix)
}
data <- cache_matrix$get()
inv_matrix <- solve(data)
cache_matrix$setinverse(inv_matrix)
return(inv_matrix)
}
x <- matrix(c(1, 2, 3, 4), nrow = 2, ncol = 2, byrow = TRUE)
m <- makeCacheMatrix(x)
# original matrix
m$get()
# first call is uncached
cacheSolve(m)
# second call is cached
cacheSolve(m)
library(datasets)
data(iris)
?iris
iris
subset(iris,Species="virgincia")
iris(,Species="virginica")
subset(iris,Species="virginica")
subset(iris,Species=="virginica")
?tapply
tapply(iris$Sepal.Length,subset(iris,Species=="virginica"),mean)
apply(subset(iris,Species=="virginica"),1,mean)
apply(subset(iris,Species=="virginica"),Sepal.Length,mean)
apply(subset(iris,Species=="virginica"),iris.Sepal.Length,mean)
sapply(iris[iris.Species=="virginica"],mean)
sapply(iris[iris$Species=="virginica"],mean)
subset(iris,Species=="virginica")
x <- subset(iris,Species=="virginica")
mean(x$Sepal.Length)
mean(subset(iris,Species=="virginica")$Sepal.Length)
apply(iris, 1, mean)
apply(iris[, 1:4], 1, mean)
apply(iris, 2, mean)
apply(iris[, 1:4], 2, mean)
?apply
library(datasets)
data(mtcars)
?mtcars
tapply(mtcars$mpg, mtcars$cyl, mean)
mtcars
set.seed(1)
rpois(5, 2)
library("swirl", lib.loc="~/R/win-library/3.2")
swirl()
x <- c(44,NA,5,NA)
x * 3
y <- rnorm(1000)
z <- rep(NA,1000)
my_data <- sample(c(y, z), 100)
my_na <- is.na(my_data)
my_na
my_data ==NA
sum(my_na)
my_data
0/0
Inf-Inf
swirl()
x
x[1:10]
x[is.na(x)]
x[!is.na(x)]
y <- x[!is.na(x)]
y
y[y>0]
x[x>0]
x[!is.na(x)&x>0]
x[c(3,5,7)]
x[0]
x[3000]
x[c(-2,-10)]
x[-c(2,10)]
vect <- c(foo = 11, bar = 2, norf = NA)
vect
names(vect)
vect2 <- c(11, 2, NA)
names(vect2) <- c("foo", "bar", "norf")
identical(vect,vect2)
vect["bar"]
vect[c("foo","bar")]
library("swirl", lib.loc="~/R/win-library/3.2")
library("httr", lib.loc="~/R/win-library/3.2")
install.packages("sqldf")
getwd()
setwd("~/GitHub/Getting-and-Cleaning-Data/")
ls
ls -al
ls()
?ls
?dir
dir()
setwd("~/GitHub/Getting-and-Cleaning-Data/")
library(plyr)
setwd("~/GitHub/Getting-and-Cleaning-Data/")
x_train <- read.table("train/X_train.txt")
setwd("~/GitHub/Getting-and-Cleaning-Data/UCI HAR Dataset/")
x_train <- read.table("train/X_train.txt")
y_train <- read.table("train/y_train.txt")
subject_train <- read.table("train/subject_train.txt")
x_test <- read.table("test/X_test.txt")
y_test <- read.table("test/y_test.txt")
subject_test <- read.table("test/subject_test.txt")
# create 'x' data set
x_data <- rbind(x_train, x_test)
# create 'y' data set
y_data <- rbind(y_train, y_test)
# create 'subject' data set
subject_data <- rbind(subject_train, subject_test)
#-------------------------------------------------------------------------------------------------------
# Step 2
# Extract only the measurements on the mean and standard deviation for each measurement
#-------------------------------------------------------------------------------------------------------
features <- read.table("features.txt")
# get only columns with mean() or std() in their names
mean_and_std_features <- grep("-(mean|std)\\(\\)", features[, 2])
# subset the desired columns
x_data <- x_data[, mean_and_std_features]
# correct the column names
names(x_data) <- features[mean_and_std_features, 2]
activities <- read.table("activity_labels.txt")
# update values with correct activity names
y_data[, 1] <- activities[y_data[, 1], 2]
# correct column name
names(y_data) <- "activity"
# correct column name
names(subject_data) <- "subject"
# bind all the data in a single data set
all_data <- cbind(x_data, y_data, subject_data)
# 66 <- 68 columns but last two (activity & subject)
tidy_data <- ddply(all_data, .(subject, activity), function(x) colMeans(x[, 1:66]))
#-------------------------------------------------------------------------------------------------------
# Step 6
# Write the tidy data set to the working directory
#-------------------------------------------------------------------------------------------------------
write.table(tidy_data, "tidy_data.txt", row.name=FALSE)
# Load Required Library
library(plyr)
# Set working Directory
setwd("~/GitHub/Getting-and-Cleaning-Data/")
#-------------------------------------------------------------------------------------------------------
# Step 1
# Merge the training and test sets to create one data set
#-------------------------------------------------------------------------------------------------------
x_train <- read.table("UCI HAR Dataset/train/X_train.txt")
y_train <- read.table("UCI HAR Dataset/train/y_train.txt")
subject_train <- read.table("UCI HAR Dataset/train/subject_train.txt")
x_test <- read.table("UCI HAR Dataset/test/X_test.txt")
y_test <- read.table("UCI HAR Dataset/test/y_test.txt")
subject_test <- read.table("UCI HAR Dataset/test/subject_test.txt")
# create 'x' data set
x_data <- rbind(x_train, x_test)
# create 'y' data set
y_data <- rbind(y_train, y_test)
# create 'subject' data set
subject_data <- rbind(subject_train, subject_test)
#-------------------------------------------------------------------------------------------------------
# Step 2
# Extract only the measurements on the mean and standard deviation for each measurement
#-------------------------------------------------------------------------------------------------------
features <- read.table("UCI HAR Dataset/features.txt")
# get only columns with mean() or std() in their names
mean_and_std_features <- grep("-(mean|std)\\(\\)", features[, 2])
# subset the desired columns
x_data <- x_data[, mean_and_std_features]
# correct the column names
names(x_data) <- features[mean_and_std_features, 2]
#-------------------------------------------------------------------------------------------------------
# Step 3
# Use descriptive activity names to name the activities in the data set
#-------------------------------------------------------------------------------------------------------
activities <- read.table("UCI HAR Dataset/activity_labels.txt")
# update values with correct activity names
y_data[, 1] <- activities[y_data[, 1], 2]
# correct column name
names(y_data) <- "activity"
#-------------------------------------------------------------------------------------------------------
# Step 4
# Appropriately label the data set with descriptive variable names
#-------------------------------------------------------------------------------------------------------
# correct column name
names(subject_data) <- "subject"
# bind all the data in a single data set
all_data <- cbind(x_data, y_data, subject_data)
#-------------------------------------------------------------------------------------------------------
# Step 5
# Create a second, independent tidy data set with the average of each variable
# for each activity and each subject
#-------------------------------------------------------------------------------------------------------
# 66 <- 68 columns but last two (activity & subject)
tidy_data <- ddply(all_data, .(subject, activity), function(x) colMeans(x[, 1:66]))
#-------------------------------------------------------------------------------------------------------
# Step 6
# Write the tidy data set to the working directory
#-------------------------------------------------------------------------------------------------------
write.table(tidy_data, "tidy_data.txt", row.name=FALSE)
